# Lab 2 扩展任务报告：GDB 调试页表查询过程

## 1. 实验背景与目的

本实验旨在深入理解 RISC-V 架构下的虚拟内存管理机制，特别是硬件 MMU（内存管理单元）如何通过页表完成虚拟地址到物理地址的转换。

在常规的操作系统开发中，我们通常认为地址转换是由硬件自动完成的“黑盒”操作。为了打破这一黑盒，本实验采用**“双重调试”（Double Debugging）**技术：
1.  **第一层**：运行 ucore 操作系统的 QEMU 模拟器。
2.  **第二层**：使用 GDB 调试正在运行的 QEMU 进程本身。

通过这种方式，我们可以直接观察 QEMU 源码中模拟硬件 MMU 行为的函数（`get_physical_address`），从而亲眼见证页表查询（Page Table Walk）、TLB 查找以及大页映射等底层细节。

---

## 2. 调试环境搭建与流程

### 2.1 准备带调试信息的 QEMU
为了能够调试 QEMU 源码，我们需要重新编译一个带有调试符号（debug symbols）的 QEMU 版本。
*   **配置命令**：`./configure --target-list=riscv64-softmmu --enable-debug`
*   **编译**：`make -j$(nproc)`
*   **修改 Makefile**：将 `ucore` 项目的 `Makefile` 中 `QEMU` 路径指向新编译的 `qemu-system-riscv64`。

### 2.2 最终验证可行的操作指南（Step-by-Step）
经过多次尝试与摸索，我们总结出了一套最稳健、能够避免死锁并精准捕获数据的操作流程。请严格按照以下顺序执行：

#### 第一阶段：启动硬件层（终端 1）
1.  **操作**：在终端 1 中输入 `make debug`。
2.  **现象**：QEMU 启动，输出启动日志，然后卡住（因 `-S` 参数暂停），等待 GDB 连接。
    *   *注意：此终端在整个过程中保持开启即可，无需额外操作。*

#### 第二阶段：初始化软件层（终端 3）
为了避免初始化阶段繁杂的内存访问干扰调试，我们采用“一步到位”的策略，直接运行到内核初始化完成的位置。
1.  **操作**：在终端 3 中输入 `make gdb`。
2.  **操作**：GDB 启动后，直接输入以下命令设置断点：
    ```gdb
    break kern/init/init.c:43
    ```
    *   *解释：第 43 行是 `kern_init` 函数末尾的 `while(1)` 死循环。停在这里意味着内存管理 (`pmm_init`) 已经全部执行完毕。*
3.  **操作**：输入 `continue`。
4.  **现象**：GDB 会运行一段时间，然后停在 `kern/init/init.c:43`。
5.  **验证**：输入 `print/x satp_virtual`。
    *   你应该能看到类似 `0xffffffff...` 的地址（例如 `0xffffffffc0205000`）。
    *   **注意**：绝不能是 `0x0`。如果非零，说明准备工作完成。

#### 第三阶段：介入上帝视角（终端 2）
现在 ucore 已经准备好，我们启动对 QEMU 本身的调试。
1.  **操作**：在终端 2 中输入 `pgrep -f qemu-system-riscv64` 获取 PID。
2.  **操作**：输入 `sudo gdb`，进入 GDB 后输入 `attach <PID>`。
3.  **操作**：输入 `handle SIGPIPE nostop noprint`（防止管道信号干扰）。
4.  **操作**：设置**条件断点**（这是防止被无关访问打断的关键）：
    ```gdb
    break get_physical_address if addr == 0xffffffffc0200000
    ```
5.  **操作**：输入 `continue`。
6.  **现象**：终端 2 会挂起（Blocking），因为它在等待 QEMU 运行，而 QEMU 目前被终端 3 暂停着。这是正常现象。

#### 第四阶段：触发与捕获（回到终端 3 -> 终端 2）
1.  **操作（终端 3）**：
    *   **极度重要**：由于之前终端 2 已经挂起（continue），此时终端 3 输入命令可能会因为等待回复而卡住。
    *   输入 `x/x 0xffffffffc0200000`。
2.  **现象**：
    *   终端 3 可能会卡住，或者报错 `Ignoring packet error` / `Cannot access memory`。
    *   **这是成功的标志！** 这说明 QEMU 已经被终端 2 的断点拦截了，无法响应终端 3 的请求。
    *   **此时请立即查看终端 2！**
3.  **现象（终端 2）**：
    *   终端 2 应该显示 `Breakpoint 1, get_physical_address ...`。
    *   恭喜你，捕获成功！现在可以直接在终端 2 进行后续观测。

#### 第五阶段：精准观测（终端 2）
现在我们已经成功拦截了这次访问，开始采集数据。为了避免按几百次 `n`，我们使用临时断点跳跃观测。
1.  **观测 SATP**：
    *   输入 `tbreak cpu_helper.c:184`（`base = ...` 行），然后 `c`。
    *   停下后，输入 `p/x env->satp` 和 `p/x base`。记录 SATP 值和页表基址。
2.  **观测页表项**：
    *   输入 `tbreak cpu_helper.c:252`（`ldq_phys` 行），然后 `c`。
    *   停下后，输入 `p/x pte_addr`（查看正在查哪一页）。
    *   输入 `n` 执行读取。
    *   输入 `p/x pte`（查看页表项内容，观察 R/W/X 位判断是否为大页）。
3.  **观测结果**：
    *   输入 `tbreak cpu_helper.c:334`（`*physical = ...` 行），然后 `c`。
    *   停下后，输入 `n` 执行赋值。
    *   输入 `p/x *physical`（查看最终计算出的物理地址）。
    *   **预期结果**：你应该看到 `0x80200000`。
        *   *验证*：这正是 ucore 内核入口点的物理地址，与我们查询的虚拟地址 `0xffffffffc0200000` 完美对应。

通过这五个阶段的操作，我们以最高的效率、最清晰的逻辑完成了本次复杂的双重调试任务。

---

## 3. 关键调试过程记录

### 3.1 寻找合适的观测时机
在实验初期，我尝试直接在 QEMU 打断点，但发现 ucore 刚启动时处于 Machine Mode（M 模式），此时尚未开启分页，地址转换是直接映射（Physical = Virtual）。

**遇到的问题**：QEMU 代码中 `if (mode == PRV_M ...)` 分支直接返回，跳过了查表逻辑。
**解决方案**：在终端 3 中，让 ucore 运行过 `pmm_init` 函数，确保 `satp` 寄存器已被写入，内核进入 Supervisor Mode（S 模式）且开启了分页机制。

### 3.2 捕获虚拟地址转换
为了精准捕获一次有效的页表查询，我采用了**条件断点**策略。
*   **目标虚拟地址**：`0xffffffffc0200000`（这是 ucore 内核的起始虚拟地址，映射到物理地址 `0x80200000`）。
*   **终端 2 设置**：
    ```gdb
    break get_physical_address if addr == 0xffffffffc0200000
    ```
*   **终端 3 触发**：
    ```gdb
    x/x 0xffffffffc0200000
    ```

### 3.3 单步调试与关键变量分析

当断点触发后，我在终端 2 中通过 GDB 单步执行（`n`），观察了 `get_physical_address` 函数的内部执行流。

#### 第一步：获取根页表基址 (SATP)
代码首先读取 `satp` 寄存器来获取根页表的物理页号（PPN）。

*   **代码片段**：
    ```c
    base = get_field(env->satp, SATP_PPN) << PGSHIFT;
    ```
*   **GDB 观测值**：
    *   `env->satp` = `0x8000000000080205`
    *   `base` = `0x180920620a0` (QEMU 内部物理地址表示)
*   **分析**：
    *   `satp` 最高位为 1，确认开启 SV39 模式。
    *   PPN = `0x80205`，说明根页表位于物理地址 `0x80205000`。

#### 第二步：页表游走 (Page Table Walk)
RISC-V SV39 采用三级页表（Level 2 -> 1 -> 0）。代码进入 `for` 循环进行查表。

*   **虚拟地址分析**：`0xffffffffc0200000`
    *   VPN[2] (Level 2 索引) = `(0xffffffffc0200000 >> 30) & 0x1ff` = `0x1ff` (511)
*   **Level 2 查表**：
    ```c
    target_ulong pte_addr = base + idx * ptesize;
    target_ulong pte = ldq_phys(cs->as, pte_addr);
    ```
*   **GDB 观测值**：
    *   `pte_addr` = `0x80205ff8`
        *   验证：`0x80205000 + 511 * 8 = 0x80205ff8`。地址计算正确，正在访问根页表的最后一项。
    *   `pte` = `0x200000cf`
        *   二进制：`... 0010 0000 0000 0000 1100 1111`

#### 第三步：发现大页映射 (Superpage)
这是本次实验最有趣的发现。

*   **代码逻辑**：
    ```c
    if (!(pte & PTE_V)) { ... } // 检查有效位
    else if (!(pte & (PTE_R | PTE_W | PTE_X))) { ... } // 检查是否指向下一级页表
    ```
*   **PTE 分析**：`0x200000cf`
    *   **V (Valid)** = 1
    *   **R/W/X** = `111` (可读、可写、可执行)
*   **结论**：
    根据 RISC-V 规范，如果 PTE 的 R/W/X 位不全为 0，则该 PTE 指向的是**物理页**（叶子节点），而不是下一级页表。
    因为我们在 Level 2（最高级）就发现了叶子节点，这说明这是一个 **1GB 的大页（Gigabyte Page）**。
    QEMU 检测到这一点后，**直接停止了循环**，没有继续查 Level 1 和 Level 0 页表。

#### 第四步：物理地址计算
*   **代码片段**：
    ```c
    *physical = (ppn | (vpn & ((1L << ptshift) - 1))) << PGSHIFT;
    ```
*   **GDB 观测值**：
    *   `*physical` = `0x80200000`
*   **验证**：
    PTE 中的 PPN 为 `0x80000`。由于是 1GB 大页，低 30 位作为页内偏移。
    最终映射：`0xffffffffc0200000` -> `0x80200000`。这与 ucore 的设计预期完全一致。

---

## 4. QEMU 模拟 TLB 与硬件 TLB 的区别

在调试过程中，我还观察到了 `tlb_fill` 函数的调用。
*   **硬件 TLB**：是 CPU 内部的高速缓存电路，容量极小，全相联或组相联，查询速度接近寄存器。
*   **QEMU 模拟 TLB**：
    *   QEMU 使用软件数据结构（如 C 语言的数组或哈希表）来模拟 TLB (`env->tlb_table`)。
    *   当 Guest OS 访问内存时，QEMU 首先查找这个软件 TLB。
    *   如果 Miss，则调用 `get_physical_address` 查表（Soft MMU），并将结果填回软件 TLB。
    *   **区别**：硬件 TLB 是并发电路，软件 TLB 是串行代码；硬件 TLB Miss 会触发硬件 Page Walker 或异常，QEMU 则是单纯的函数调用。

---

## 5. 大模型辅助实验记录

在本次实验中，我遇到了多个棘手问题，通过与大模型（AI 助手）的交互得到了有效解决。

### 场景 1：双重调试时的“死锁”现象
*   **问题情景**：当我同时在终端 2（QEMU GDB）和终端 3（ucore GDB）操作时，经常出现两个终端都卡死不动的情况。
*   **我的困惑**：我不确定是哪个 GDB 挂起了，也不敢随意按 Ctrl+C，怕破坏环境。
*   **与大模型交互**：
    *   我描述了“终端 3 执行 `n` 卡死，终端 2 也在等待”的现象。
    *   大模型分析指出：终端 2 是“上帝”，如果它停在断点上，QEMU 进程就会挂起，导致终端 3 失去响应。必须先在终端 2 输入 `continue`。
    *   **解决思路**：大模型建议我采用“分阶段”策略：先让 ucore 跑完初始化（不挂载 QEMU GDB），等页表建好后，再连接 QEMU GDB 进行拦截。这个策略非常奏效，彻底解决了死锁问题。

### 场景 2：GDB 打印变量的误解
*   **问题情景**：在观察 `*physical` 变量时，GDB 输出了 `$3 = 0x5603a5be9bb0`，我以为算出的物理地址错了。
*   **与大模型交互**：
    *   我把日志发给大模型，询问为什么物理地址是一个宿主机的虚拟地址。
    *   大模型敏锐地指出：`physical` 在 C 代码中是一个指针参数 (`hwaddr *physical`)。直接 `print physical` 打印的是指针本身的地址（栈地址），而不是它指向的值。
    *   **解决**：指导我使用 `print *physical` 或 `print/x *physical` 来解引用，最终成功看到了 `0x80200000`。

### 场景 3：如何精准捕获目标地址
*   **问题情景**：我在 QEMU 中打断点后，总是被一些莫名其妙的地址（如取指、设备访问）频繁中断，很难抓到我关心的内核地址。
*   **与大模型交互**：
    *   我询问如何过滤这些无关中断。
    *   大模型教会了我 GDB 的 **条件断点** 语法：`break get_physical_address if addr == 0xffffffffc0200000`。
    *   这大大提高了调试效率，让我能一键直达核心现场。

---

## 6. 实验心得
本次实验是一次极具挑战性的“俄罗斯套娃”式调试体验。通过直接解剖 QEMU 源码，原本抽象的“页表游走”、“大页映射”概念变得具象化了。我不仅掌握了 RISC-V SV39 的细节，还学会了如何利用调试器探索大型开源项目（QEMU）的内部逻辑，这对理解计算机系统底层原理大有裨益。
